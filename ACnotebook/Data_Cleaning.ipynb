{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e75ba89",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "The following code will transform the raw data into expected format and report the rows with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9c2806a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "3166a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path for the raw data csv file\n",
    "file_path = '/Users/fuwang/Documents/Web Scraper/Tickets 2/JapanesePaper/ac_dataset.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "26bb5898",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Report Number'] = df['Report Number'].apply(lambda x: str(x).replace(u'\\xa0', ''))\n",
    "df['Report Number'] = df['Report Number'].replace('',np.nan,regex=True)\n",
    "df.dropna(axis=0,how='all',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bffc680",
   "metadata": {},
   "source": [
    "## Extract Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "cd1f14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions that to extract the time from raw data\n",
    "def extract_time(df):\n",
    "    for i in range(len(df['Report Number'])):\n",
    "        if df['Report Number'].iloc[i].startswith('The'):\n",
    "            df['Report Number'].iloc[i] = df['Report Number'].iloc[i][-8:]\n",
    "    df.drop(df.tail(3).index,inplace=True) # drop last n rows\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a467b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['Report Number'])):\n",
    "    if df['Report Number'].iloc[i].startswith('The'):\n",
    "        df['Report Number'].iloc[i] = df['Report Number'].iloc[i][-8:]\n",
    "\n",
    "df.drop(df.tail(3).index,inplace=True) # drop last n rows\n",
    "df['Report Number'] = df['Report Number'].str.rstrip(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9ed7bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = None\n",
    "df['File Name'] = None\n",
    "df = df.astype(str)\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i]['Report Number'][0].isdigit():\n",
    "        temp = df.iloc[i]['Report Number']\n",
    "    df['Year'].iloc[i] = temp\n",
    "    df['File Name'].iloc[i] = df.iloc[i][0]+'.'+df.iloc[i][1]+'.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "46a1c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_year = df[df['Report Number'].str[0].str.isdigit()].index\n",
    "df.drop(index_year,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ec222c",
   "metadata": {},
   "source": [
    "## Extract Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "0d8d5e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['author'] = df['author'].str.slice(start=3)\n",
    "df['author'] = df['author'].str.replace(', and',',')\n",
    "df['author'] = df['author'].str.replace('and',',')\n",
    "df['author'] = df['author'].apply(lambda x: str(x).replace(u'\\xa0', ''))\n",
    "df['author'] = df['author'].replace(r'\\s+', ' ', regex=True)\n",
    "df.author=df.author.str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b1ac54cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_authors(df):\n",
    "    max_num_authors = len(max(df.author,key=len))\n",
    "    authors = []\n",
    "    for i in range(max_num_authors):\n",
    "        authors.append(f'Author {i+1}')\n",
    "    for i in range(max_num_authors):\n",
    "        df[f'Author {i+1}'] = None\n",
    "    for i in range(len(df.author)):\n",
    "        for j in range(len(df.author.iloc[i])):\n",
    "            df[f'Author {j+1}'].iloc[i] =  df.author.iloc[i][j].strip()\n",
    "    for i in range(max_num_authors):\n",
    "        df[f'Author {i+1}'] = df[f'Author {i+1}'].str.replace(' ',',')\n",
    "    return authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e22f756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = extract_authors(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb98961",
   "metadata": {},
   "source": [
    "## Detect Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7767232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_detect(df):\n",
    "    outlier_index = []\n",
    "    outlier_number = []\n",
    "    df['is_outlier'] = 'no'\n",
    "    for i in range(df.shape[0]):\n",
    "        if df['title'].iloc[i] == 'nan' or df.outlier.iloc[i] != 'nan':\n",
    "            outlier_index.append(i)\n",
    "            outlier_number.append(df['Report Number'].iloc[i])\n",
    "            df['is_outlier'].iloc[i] = 'yes'\n",
    "    return df.iloc[outlier_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "04236478",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_df = outlier_detect(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "2aac7d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Outlier CSV file to expected path\n",
    "outlier_df.to_csv('/Users/fuwang/Documents/Web Scraper/Tickets 2/JapanesePaper/outlier.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1d61d4",
   "metadata": {},
   "source": [
    "## Export Metada to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "b1cd145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df[['title','Year','Report Number'] +authors+\n",
    "       ['File Name']]\n",
    "df_new.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "32676f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export CSV file to the work path you prefered \n",
    "df_new.to_csv('/Users/fuwang/Documents/Web Scraper/Tickets 2/JapanesePaper/cleandf.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8cb5f9",
   "metadata": {},
   "source": [
    "## Down PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "3f6f3a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert links \n",
    "# allowed_domains = 'business.columbia.edu'\n",
    "df['downloadable'] = None\n",
    "for i in range(df.shape[0]):\n",
    "    if df.link.iloc[i][:6] == '/sites':\n",
    "        df.link.iloc[i] = 'https://business.columbia.edu' + df.link.iloc[i]\n",
    "        df['downloadable'].iloc[i] = 'direct link'\n",
    "    elif df.link.iloc[i][:10] == 'http://hdl' or df['is_outlier'].iloc[i]=='yes':\n",
    "        df['downloadable'].iloc[i] = 'invalid link'\n",
    "    else: df['downloadable'].iloc[i] = 'indirect link'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "247b40a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadFile(url, fileName):\n",
    "    with open(fileName, \"wb\") as file:\n",
    "        response = requests.get(url, timeout = 0.5)\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a605d19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will download all pdf files which has a valid direct downloadable link\n",
    "for i in range(df.shape[0]):\n",
    "    if df.is_outlier.iloc[i] != 'yes':\n",
    "        try:\n",
    "            downloadFile(df.link.iloc[i],df['File Name'].iloc[i])\n",
    "        except requests.exceptions.Timeout:\n",
    "              print (\"Timeout occurred\")        \n",
    "    else: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "f458618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the files need to be download mannually\n",
    "def manual_download(df):\n",
    "    report_number = []\n",
    "    link = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if df['downloadable'].iloc[i] == 'indirect link':\n",
    "            report_number.append(df['Report Number'].iloc[i])\n",
    "            link.append(df['link'].iloc[i])\n",
    "    \n",
    "    return report_number,link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "1aa339d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "report, link = manual_download(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ca2aac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_df = pd.DataFrame({'Report Number':report,'Link':link})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "727b5b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export manually CSV file to the work path you prefered \n",
    "manual_df.to_csv('/Users/fuwang/Documents/Web Scraper/Tickets 2/JapanesePaper/indirect_link.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c21907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
